{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optax\n",
      "  Downloading optax-0.2.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: jax[cuda12] in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (0.5.3)\n",
      "Requirement already satisfied: jaxlib<=0.5.3,>=0.5.3 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jax[cuda12]) (0.5.3)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jax[cuda12]) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.25 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jax[cuda12]) (2.1.3)\n",
      "Requirement already satisfied: opt_einsum in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jax[cuda12]) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jax[cuda12]) (1.15.2)\n",
      "Collecting jax-cuda12-plugin<=0.5.3,>=0.5.3 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading jax_cuda12_plugin-0.5.3-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from optax) (2.2.2)\n",
      "Collecting chex>=0.1.87 (from optax)\n",
      "  Downloading chex-0.1.89-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting etils[epy] (from optax)\n",
      "  Downloading etils-1.12.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.2.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from chex>=0.1.87->optax) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from chex>=0.1.87->optax) (75.8.0)\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.87->optax)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jax-cuda12-pjrt==0.5.3 (from jax-cuda12-plugin<=0.5.3,>=0.5.3->jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading jax_cuda12_pjrt-0.5.3-py3-none-manylinux2014_x86_64.whl.metadata (492 bytes)\n",
      "Collecting nvidia-cublas-cu12>=12.1.3.1 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12>=12.6.85 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cuda_nvcc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.1 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cudnn_cu12-9.8.0.87-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cufft-cu12>=11.0.2.54 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12>=11.4.5.107 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12>=12.1.0.106 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nccl-cu12>=2.18.1 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_nccl_cu12-2.26.2.post1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvjitlink-cu12>=12.1.105 (from jax-cuda12-plugin[with_cuda]<=0.5.3,>=0.5.3; extra == \"cuda12\"->jax[cuda12])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Downloading optax-0.2.4-py3-none-any.whl (319 kB)\n",
      "Downloading chex-0.1.89-py3-none-any.whl (99 kB)\n",
      "Downloading jax_cuda12_plugin-0.5.3-cp312-cp312-manylinux2014_x86_64.whl (16.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jax_cuda12_pjrt-0.5.3-py3-none-manylinux2014_x86_64.whl (104.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.7/104.7 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m\n",
      "Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvcc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.8.0.87-py3-none-manylinux_2_27_x86_64.whl (698.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.0/698.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2.post1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (291.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.7/291.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading etils-1.12.2-py3-none-any.whl (167 kB)\n",
      "Installing collected packages: jax-cuda12-pjrt, toolz, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jax-cuda12-plugin, etils, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, chex, optax\n",
      "Successfully installed chex-0.1.89 etils-1.12.2 jax-cuda12-pjrt-0.5.3 jax-cuda12-plugin-0.5.3 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvcc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.8.0.87 nvidia-cufft-cu12-11.3.3.83 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.26.2.post1 nvidia-nvjitlink-cu12-12.8.93 optax-0.2.4 toolz-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"jax[cuda12]\" optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jax\n",
      "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax)\n",
      "  Downloading jaxlib-0.5.3-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jax) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.25 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jax) (2.1.3)\n",
      "Requirement already satisfied: opt_einsum in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jax) (3.4.0)\n",
      "Collecting scipy>=1.11.1 (from jax)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading jax-0.5.3-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.5.3-cp312-cp312-manylinux2014_x86_64.whl (105.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Installing collected packages: scipy, jaxlib, jax\n",
      "Successfully installed jax-0.5.3 jaxlib-0.5.3 scipy-1.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "!pip install -q -U kagglehub --upgrade\n",
    "!pip install jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 11 04:21:02 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off |   00000000:01:00.0 Off |                  Off |\n",
      "|  0%   47C    P8             16W /  450W |     113MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1993      G   /usr/lib/xorg/Xorg                             84MiB |\n",
      "|    0   N/A  N/A      2143      G   /usr/bin/gnome-shell                           15MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.1.0 pyparsing-3.2.3\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 04:21:17.906127: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744325478.019873  107029 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744325478.049757  107029 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744325478.317504  107029 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744325478.317523  107029 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744325478.317525  107029 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744325478.317526  107029 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\" # you can also use tensorflow or torch\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\" # avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"\"\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"  # Avoid preallocating all GPU memory\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.8\"  # Use 80% of GPU memory\n",
    "import keras\n",
    "import keras_nlp\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# os.environ[\"KAGGLE_USERNAME\"] = user_secrets.get_secret(\"kaggle_username\")\n",
    "# os.environ[\"KAGGLE_KEY\"] = user_secrets.get_secret(\"kaggle_key\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas() # progress bar for pandas\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 42\n",
    "    dataset_path = \"/kaggle/input/kaggle-docs/questions_answers\"\n",
    "    preset = \"gemma_2b_en\"  # Pretrained Gemma model\n",
    "    sequence_length = 512   # Max sequence length for training chunks\n",
    "    batch_size = 1          # Batch size\n",
    "    lora_rank = 5           # LoRA rank\n",
    "    learning_rate = 3e-4    # Learning rate\n",
    "    epochs = 15             # Number of epochs\n",
    "    validation_split = 0.2  # 20% of data for validation\n",
    "    early_stopping_patience = 3  # Stop if no improvement after 3 epochs\n",
    "    stride = 256            # Stride for sliding window\n",
    "    checkpoint_dir=\"./checkpoints_gemma_2b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(Config.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_non_string_rows(df):\n",
    "    df = df[df.iloc[:, 5].apply(lambda x: isinstance(x, str))]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​thank u, next</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​God is a woman</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>Dangerous Woman</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​no tears left to cry</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1         Artist                   Title            Album  \\\n",
       "0             0  Ariana Grande          ​thank u, next    thank u, next   \n",
       "1             1  Ariana Grande                 7 rings    thank u, next   \n",
       "2             2  Ariana Grande         ​God is a woman        Sweetener   \n",
       "3             3  Ariana Grande            Side To Side  Dangerous Woman   \n",
       "4             4  Ariana Grande  ​​no tears left to cry        Sweetener   \n",
       "\n",
       "         Date                                              Lyric    Year  \\\n",
       "0  2018-11-03  thought i'd end up with sean but he wasn't a m...  2018.0   \n",
       "1  2019-01-18  yeah breakfast at tiffany's and bottles of bub...  2019.0   \n",
       "2  2018-07-13  you you love it how i move you you love it how...  2018.0   \n",
       "3  2016-05-20  ariana grande  nicki minaj i've been here all ...  2016.0   \n",
       "4  2018-04-20  right now i'm in a state of mind i wanna be in...  2018.0   \n",
       "\n",
       "   Unnamed: 0  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./MERGED_SONG_LYRIC_DATA.csv\")\n",
    "\n",
    "df = filter_non_string_rows(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export KAGGLE_USERNAME=malaydamani\n",
    "!export KAGGLE_KEY=733ca2e5335e338ca6d13e1b79891905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_USERNAME\"]=\"malaydamani\"\n",
    "os.environ[\"KAGGLE_KEY\"]=\"733ca2e5335e338ca6d13e1b79891905\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 04:22:35.749336: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "I0000 00:00:1744325555.749979  107029 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5775 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Lyric'].apply(lambda x: x.strip().lower()) != \"the rest of the lyrics coming soon\"]\n",
    "df = df[df['Lyric'].apply(lambda x: x.strip().lower()) != \"come back soon when there is lyrics\"]\n",
    "df = df[df['Lyric'].apply(lambda x: x.strip().lower()) != \"lyrics will be provided at release\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Artist\"] != \"BTS (방탄소년단)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyric_length']=df['Lyric'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Lyric'].apply(lambda x: x.strip().lower()) != \"the rest of the lyrics coming soon\"]\n",
    "df = df[df['Lyric'].apply(lambda x: x.strip().lower()) != \"come back soon when there is lyrics\"]\n",
    "df = df[df['Lyric'].apply(lambda x: x.strip().lower()) != \"lyrics will be provided at release\"]\n",
    "df = df[df['lyric_length'] > 50]\n",
    "# df = df[df['Lyric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Give me a song titled \\\"{Title}\\\" in style of artist \\\"{Artist}\\\"\\n\\n\\nSong:\\n{Song}\"\n",
    "df[\"prompt\"] = df.apply(\n",
    "    lambda row: template.format(\n",
    "        Artist=row.Artist.lower(),\n",
    "        Title=row.Title.lower(),\n",
    "        Song=row.Lyric.lower() + \" [EOS]\"  # [EOS] added to the end of the full lyric\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "data = df.prompt.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPU RAM: 122.02 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get available system memory\n",
    "memory = psutil.virtual_memory()\n",
    "\n",
    "# Print available memory\n",
    "print(f\"Available CPU RAM: {memory.available / (1024 ** 3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU RAM: 23.5263671875 GB / 23.98828125 GB\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpu_memory():\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.free,memory.total', '--format=csv,nounits,noheader'], stdout=subprocess.PIPE)\n",
    "    output = result.stdout.decode('utf-8').strip()\n",
    "    \n",
    "    # Parse output (assuming one GPU)\n",
    "    free_memory, total_memory = map(int, output.split(', '))\n",
    "    \n",
    "    print(f\"Available GPU RAM: {free_memory / 1024} GB / {total_memory / 1024} GB\")\n",
    "    \n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lyric_length</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​thank u, next</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2305</td>\n",
       "      <td>Give me a song titled \"​thank u, next\" in styl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2184</td>\n",
       "      <td>Give me a song titled \"7 rings\" in style of ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​God is a woman</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975</td>\n",
       "      <td>Give me a song titled \"​god is a woman\" in sty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>Dangerous Woman</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2727</td>\n",
       "      <td>Give me a song titled \"side to side\" in style ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​no tears left to cry</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2307</td>\n",
       "      <td>Give me a song titled \"​​no tears left to cry\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1         Artist                   Title            Album  \\\n",
       "0             0  Ariana Grande          ​thank u, next    thank u, next   \n",
       "1             1  Ariana Grande                 7 rings    thank u, next   \n",
       "2             2  Ariana Grande         ​God is a woman        Sweetener   \n",
       "3             3  Ariana Grande            Side To Side  Dangerous Woman   \n",
       "4             4  Ariana Grande  ​​no tears left to cry        Sweetener   \n",
       "\n",
       "         Date                                              Lyric    Year  \\\n",
       "0  2018-11-03  thought i'd end up with sean but he wasn't a m...  2018.0   \n",
       "1  2019-01-18  yeah breakfast at tiffany's and bottles of bub...  2019.0   \n",
       "2  2018-07-13  you you love it how i move you you love it how...  2018.0   \n",
       "3  2016-05-20  ariana grande  nicki minaj i've been here all ...  2016.0   \n",
       "4  2018-04-20  right now i'm in a state of mind i wanna be in...  2018.0   \n",
       "\n",
       "   Unnamed: 0  lyric_length                                             prompt  \n",
       "0         NaN          2305  Give me a song titled \"​thank u, next\" in styl...  \n",
       "1         NaN          2184  Give me a song titled \"7 rings\" in style of ar...  \n",
       "2         NaN          1975  Give me a song titled \"​god is a woman\" in sty...  \n",
       "3         NaN          2727  Give me a song titled \"side to side\" in style ...  \n",
       "4         NaN          2307  Give me a song titled \"​​no tears left to cry\"...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Year</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lyric_length</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​thank u, next</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>thought i'd end up with sean but he wasn't a m...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2305</td>\n",
       "      <td>Give me a song titled \"​thank u, next\" in styl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>yeah breakfast at tiffany's and bottles of bub...</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2184</td>\n",
       "      <td>Give me a song titled \"7 rings\" in style of ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​God is a woman</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>you you love it how i move you you love it how...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975</td>\n",
       "      <td>Give me a song titled \"​god is a woman\" in sty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Side To Side</td>\n",
       "      <td>Dangerous Woman</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>ariana grande  nicki minaj i've been here all ...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2727</td>\n",
       "      <td>Give me a song titled \"side to side\" in style ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>​​no tears left to cry</td>\n",
       "      <td>Sweetener</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>right now i'm in a state of mind i wanna be in...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2307</td>\n",
       "      <td>Give me a song titled \"​​no tears left to cry\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>6020</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Rare Peer (Brenda Lee Tribute)</td>\n",
       "      <td>Woman Walk The Line</td>\n",
       "      <td>2017-09-20</td>\n",
       "      <td>i'm curled up in my mother's bed staring inten...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>2524</td>\n",
       "      <td>Give me a song titled \"rare peer (brenda lee t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>6021</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Should’ve Said No (Live from Clear Channel Str...</td>\n",
       "      <td>Live From Clear Channel Stripped 2008</td>\n",
       "      <td>2008-06-28</td>\n",
       "      <td>it's strange to think the songs we used to sin...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>1748</td>\n",
       "      <td>Give me a song titled \"should’ve said no (live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>6022</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Teardrops on my Guitar (Live from Clear Channe...</td>\n",
       "      <td>Live From Clear Channel Stripped 2008</td>\n",
       "      <td>2008-06-28</td>\n",
       "      <td>drew looks at me i fake a smile so he won't se...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>1374</td>\n",
       "      <td>Give me a song titled \"teardrops on my guitar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>6024</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Welcome Back Grunwald</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>turn wycd on you're on your grunwald back from...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>476.0</td>\n",
       "      <td>317</td>\n",
       "      <td>Give me a song titled \"welcome back grunwald\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>6026</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Find you</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trying just like they say just taking the step...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>478.0</td>\n",
       "      <td>395</td>\n",
       "      <td>Give me a song titled \"find you\" in style of a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5097 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1         Artist  \\\n",
       "0                0  Ariana Grande   \n",
       "1                1  Ariana Grande   \n",
       "2                2  Ariana Grande   \n",
       "3                3  Ariana Grande   \n",
       "4                4  Ariana Grande   \n",
       "...            ...            ...   \n",
       "5616          6020   Taylor Swift   \n",
       "5617          6021   Taylor Swift   \n",
       "5618          6022   Taylor Swift   \n",
       "5620          6024   Taylor Swift   \n",
       "5622          6026   Taylor Swift   \n",
       "\n",
       "                                                  Title  \\\n",
       "0                                        ​thank u, next   \n",
       "1                                               7 rings   \n",
       "2                                       ​God is a woman   \n",
       "3                                          Side To Side   \n",
       "4                                ​​no tears left to cry   \n",
       "...                                                 ...   \n",
       "5616                     Rare Peer (Brenda Lee Tribute)   \n",
       "5617  Should’ve Said No (Live from Clear Channel Str...   \n",
       "5618  Teardrops on my Guitar (Live from Clear Channe...   \n",
       "5620                              Welcome Back Grunwald   \n",
       "5622                                           Find you   \n",
       "\n",
       "                                       Album        Date  \\\n",
       "0                              thank u, next  2018-11-03   \n",
       "1                              thank u, next  2019-01-18   \n",
       "2                                  Sweetener  2018-07-13   \n",
       "3                            Dangerous Woman  2016-05-20   \n",
       "4                                  Sweetener  2018-04-20   \n",
       "...                                      ...         ...   \n",
       "5616                    Woman Walk The Line   2017-09-20   \n",
       "5617  Live From Clear Channel Stripped 2008   2008-06-28   \n",
       "5618  Live From Clear Channel Stripped 2008   2008-06-28   \n",
       "5620                                     NaN         NaN   \n",
       "5622                                     NaN         NaN   \n",
       "\n",
       "                                                  Lyric    Year  Unnamed: 0  \\\n",
       "0     thought i'd end up with sean but he wasn't a m...  2018.0         NaN   \n",
       "1     yeah breakfast at tiffany's and bottles of bub...  2019.0         NaN   \n",
       "2     you you love it how i move you you love it how...  2018.0         NaN   \n",
       "3     ariana grande  nicki minaj i've been here all ...  2016.0         NaN   \n",
       "4     right now i'm in a state of mind i wanna be in...  2018.0         NaN   \n",
       "...                                                 ...     ...         ...   \n",
       "5616  i'm curled up in my mother's bed staring inten...  2017.0       472.0   \n",
       "5617  it's strange to think the songs we used to sin...  2008.0       473.0   \n",
       "5618  drew looks at me i fake a smile so he won't se...  2008.0       474.0   \n",
       "5620  turn wycd on you're on your grunwald back from...     NaN       476.0   \n",
       "5622  trying just like they say just taking the step...     NaN       478.0   \n",
       "\n",
       "      lyric_length                                             prompt  \n",
       "0             2305  Give me a song titled \"​thank u, next\" in styl...  \n",
       "1             2184  Give me a song titled \"7 rings\" in style of ar...  \n",
       "2             1975  Give me a song titled \"​god is a woman\" in sty...  \n",
       "3             2727  Give me a song titled \"side to side\" in style ...  \n",
       "4             2307  Give me a song titled \"​​no tears left to cry\"...  \n",
       "...            ...                                                ...  \n",
       "5616          2524  Give me a song titled \"rare peer (brenda lee t...  \n",
       "5617          1748  Give me a song titled \"should’ve said no (live...  \n",
       "5618          1374  Give me a song titled \"teardrops on my guitar ...  \n",
       "5620           317  Give me a song titled \"welcome back grunwald\" ...  \n",
       "5622           395  Give me a song titled \"find you\" in style of a...  \n",
       "\n",
       "[5097 rows x 10 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_eng_non_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        :[]​\n",
       "1         :[]\n",
       "2        :[]​\n",
       "3         :[]\n",
       "4        :[]​\n",
       "        ...  \n",
       "5618    ():[]\n",
       "5619      :[]\n",
       "5620      :[]\n",
       "5621    ():[]\n",
       "5622      :[]\n",
       "Name: non_eng_non_alpha_chars, Length: 5623, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cloned = df.copy()\n",
    "\n",
    "def find_non_english_non_alphanumeric(text):\n",
    "    # if isinstance(text, str):\n",
    "        special_chars = re.findall(r'[^\\w\\s\\.,\\'\"]', text+\"\")\n",
    "        # non_eng_non_alpha = re.findall(r'[^\\w\\s]', text)\n",
    "        return \"\".join(sorted(list(set(special_chars))))\n",
    "    # return \"\"\n",
    "\n",
    "df_cloned['non_eng_non_alpha_chars'] = df_cloned['prompt'].apply(find_non_english_non_alphanumeric)\n",
    "\n",
    "df_cloned[\"non_eng_non_alpha_chars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0.1, Artist, Title, Album, Date, Lyric, Year, Unnamed: 0, lyric_length, prompt, non_eng_non_alpha_chars]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "non_empty_special_chars_df = df_cloned[df_cloned['non_eng_non_alpha_chars'] != '']\n",
    "\n",
    "print(non_empty_special_chars_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '[']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[^\\w\\s\\.,\\'\"]', \"Hi! THis is me[\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1                                                            6023\n",
       "Artist                                                          Taylor Swift\n",
       "Title                                                     Evermore [Forward]\n",
       "Album                                                                    NaN\n",
       "Date                                                              2020-12-11\n",
       "Lyric                      to put it plainly we just couldnt stop writing...\n",
       "Year                                                                  2020.0\n",
       "Unnamed: 0                                                             475.0\n",
       "lyric_length                                                             744\n",
       "prompt                     Give me a song titled \"evermore [forward]\" in ...\n",
       "non_eng_non_alpha_chars                                                     \n",
       "Name: 5619, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cloned.iloc[5619]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaQA:\n",
    "    def __init__(self, max_length=256):\n",
    "        self.max_length = max_length\n",
    "        self.prompt = template\n",
    "        self.gemma_causal_lm = gemma_lm\n",
    "\n",
    "    def query(self, artist,title):\n",
    "        response = self.gemma_causal_lm.generate(\n",
    "            self.prompt.format(\n",
    "                Artist=artist,\n",
    "                Title=title,\n",
    "                Song=\"\"),\n",
    "            max_length=self.max_length)\n",
    "        display(Markdown(colorize_text(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=3,  # Stop after 3 epochs of no improvement\n",
    "    restore_best_weights=True,  # Restore weights from the best epoch\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3936, Validation size: 1124, Test size: 563\n"
     ]
    }
   ],
   "source": [
    "data = df.prompt.tolist()\n",
    "\n",
    "# Train-Val-Test Split (70-20-10)\n",
    "train_data, temp_data = train_test_split(data, train_size=0.7, random_state=Config.seed)\n",
    "val_data, test_data = train_test_split(temp_data, train_size=0.6667, random_state=Config.seed)  # 0.6667 of 30% ≈ 20% of total\n",
    "\n",
    "print(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}, Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = gemma_lm.preprocessor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sliding_window_tokenization(texts, sequence_length, stride):\n",
    "    all_token_ids = []\n",
    "    eos_token_id = tokenizer.token_to_id(\"[EOS]\") or tokenizer.eos_token_id\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    for text in texts:\n",
    "        token_ids = np.array(tokenizer(text).tolist())\n",
    "        \n",
    "        # Handle short sequences (len <= sequence_length)\n",
    "        if len(token_ids) <= sequence_length:\n",
    "            if len(token_ids) == sequence_length:\n",
    "                token_ids[-1] = eos_token_id  # Replace last token if exactly sequence_length\n",
    "            else:\n",
    "                # Truncate to sequence_length - 1 if needed, then append [EOS]\n",
    "                token_ids = token_ids[:sequence_length - 1]\n",
    "                token_ids = np.append(token_ids, eos_token_id)\n",
    "                # Pad if still shorter than sequence_length\n",
    "                if len(token_ids) < sequence_length:\n",
    "                    token_ids = np.pad(token_ids, (0, sequence_length - len(token_ids)), \n",
    "                                     constant_values=pad_token_id)\n",
    "            all_token_ids.append(token_ids)\n",
    "        else:\n",
    "            # Handle long sequences with sliding window\n",
    "            for i in range(0, len(token_ids), stride):\n",
    "                chunk = token_ids[i:i + sequence_length]\n",
    "                if len(chunk) == sequence_length:\n",
    "                    chunk[-1] = eos_token_id  # Replace last token with [EOS]\n",
    "                else:\n",
    "                    # For the last chunk, truncate to sequence_length - 1, append [EOS], and pad\n",
    "                    chunk = chunk[:sequence_length - 1]\n",
    "                    chunk = np.append(chunk, eos_token_id)\n",
    "                    if len(chunk) < sequence_length:\n",
    "                        chunk = np.pad(chunk, (0, sequence_length - len(chunk)), \n",
    "                                     constant_values=pad_token_id)\n",
    "                all_token_ids.append(chunk)\n",
    "    \n",
    "    # Convert to NumPy array and verify shape\n",
    "    result = np.array(all_token_ids)\n",
    "    assert all(len(seq) == sequence_length for seq in result), \"Inconsistent sequence lengths\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in gemma_lm.backbone.layers[:-5]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = sliding_window_tokenization(data, Config.sequence_length, Config.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, val_data = train_test_split(\n",
    "#     tokenized_data, \n",
    "#     test_size=Config.validation_split, \n",
    "#     random_state=Config.seed\n",
    "# )\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    data, \n",
    "    test_size=Config.validation_split, \n",
    "    random_state=Config.seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in gemma_lm.backbone.layers[:-5]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = gemma_lm.preprocessor.tokenizer\n",
    "# def preprocess_data(texts):\n",
    "#     return tokenizer(texts, max_length=Config.sequence_length, padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_lm.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=Config.learning_rate),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    weighted_metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(Config.checkpoint_dir, \"checkpoint_epoch_{epoch:02d}.weights.h5\")\n",
    "latest_checkpoint = None\n",
    "if os.path.exists(Config.checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(Config.checkpoint_dir) if f.startswith(\"checkpoint_epoch_\") and f.endswith(\".weights.h5\")]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=lambda x: int(x.split(\"_\")[2].split(\".\")[0]))\n",
    "        latest_checkpoint = os.path.join(Config.checkpoint_dir, latest_checkpoint)\n",
    "        print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n",
    "        gemma_lm.load_weights(latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=Config.early_stopping_patience,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    save_freq= len(train_data) // Config.batch_size,  # Save every epoch\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "initial_epoch = 0\n",
    "if latest_checkpoint:\n",
    "    initial_epoch = int(latest_checkpoint.split(\"_\")[2].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a song titled \"​everytime (live)\" in style of artist \"ariana grande\"\n",
      "\n",
      "\n",
      "Song:\n",
      "shee let's go   i get tired of your noshows you get tired of my control yeah they keep tellin' me to let go but i don't really let go when i say so yuh yuh yuh i keep givin' people blank stares yeah i'm so different when you're not there it's like something out of shakespeare 'cause i'm really not here not there  pre i've tried to fight our energy baby but every time i think i'm free come on let's go   you get high and call on the regular i get weak and fall like a teenager why oh why does god keep bringing me back to you said back to you baby i get drunk pre tend that i'm over it selfdestruct show up like an idiot why oh why does god keep bringing me back to you  post yeah yeah i go back to you back to you back to you back to you oh back to you back to you back to you said back to you i go back to you back to you back to you every time to you you baby yeah oh yeah yeah yeah i go back to you back to you back to you back to you back to you back to you i go i go back to you back to you back to you every time [EOS]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 23:07:35.975682: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT64 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 23:07:48.902667: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 10.47GiB (11239587271 bytes) by rematerialization; only reduced to 15.37GiB (16504125764 bytes), down from 15.78GiB (16940350460 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/4498\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21:51:47\u001b[0m 18s/step - accuracy: 0.4797 - loss: 0.8446"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 23:07:55.160535: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 10.47GiB (11239587271 bytes) by rematerialization; only reduced to 15.37GiB (16504125764 bytes), down from 15.78GiB (16940350460 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5512 - loss: 1.1874   \n",
      "Epoch 2: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_02.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m805s\u001b[0m 177ms/step - accuracy: 0.5512 - loss: 1.1874\n",
      "Epoch 3/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5403 - loss: 1.2949   \n",
      "Epoch 3: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_03.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 177ms/step - accuracy: 0.5404 - loss: 1.2948\n",
      "Epoch 4/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.6243 - loss: 0.8942   \n",
      "Epoch 4: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_04.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 177ms/step - accuracy: 0.6243 - loss: 0.8942\n",
      "Epoch 5/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.6764 - loss: 0.7182   \n",
      "Epoch 5: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_05.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 177ms/step - accuracy: 0.6764 - loss: 0.7182\n",
      "Epoch 6/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7302 - loss: 0.5560   \n",
      "Epoch 6: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_06.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 177ms/step - accuracy: 0.7302 - loss: 0.5560\n",
      "Epoch 7/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7715 - loss: 0.4429   \n",
      "Epoch 7: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_07.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 178ms/step - accuracy: 0.7715 - loss: 0.4429\n",
      "Epoch 8/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7997 - loss: 0.3736   \n",
      "Epoch 8: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_08.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 178ms/step - accuracy: 0.7997 - loss: 0.3736\n",
      "Epoch 9/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8151 - loss: 0.3352   \n",
      "Epoch 9: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_09.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 177ms/step - accuracy: 0.8151 - loss: 0.3352\n",
      "Epoch 10/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8162 - loss: 0.3260   \n",
      "Epoch 10: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_10.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 177ms/step - accuracy: 0.8162 - loss: 0.3260\n",
      "Epoch 11/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8116 - loss: 0.3334   \n",
      "Epoch 11: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_11.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 177ms/step - accuracy: 0.8116 - loss: 0.3334\n",
      "Epoch 12/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7717 - loss: 0.4207   \n",
      "Epoch 12: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_12.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 177ms/step - accuracy: 0.7717 - loss: 0.4207\n",
      "Epoch 13/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7704 - loss: 0.4268   \n",
      "Epoch 13: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_13.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 177ms/step - accuracy: 0.7704 - loss: 0.4268\n",
      "Epoch 14/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7921 - loss: 0.3747   \n",
      "Epoch 14: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_14.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m799s\u001b[0m 178ms/step - accuracy: 0.7921 - loss: 0.3747\n",
      "Epoch 15/15\n",
      "\u001b[1m4497/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7989 - loss: 0.3517   \n",
      "Epoch 15: saving model to ./checkpoints_gemma_2b/checkpoint_epoch_15.weights.h5\n",
      "\u001b[1m4498/4498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 177ms/step - accuracy: 0.7989 - loss: 0.3517\n"
     ]
    }
   ],
   "source": [
    "history = gemma_lm.fit(\n",
    "    x=train_data,\n",
    "    # y=train_data[:, 1:],\n",
    "    # validation_data=val_data,batch\n",
    "    batch_size=Config.batch_size,\n",
    "    epochs=Config.epochs,\n",
    "    initial_epoch=initial_epoch,\n",
    "    callbacks=[early_stopping, best_checkpoint, resume_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaQA:\n",
    "    def __init__(self, max_length=1024):  # Increased max_length for longer songs\n",
    "        self.max_length = max_length\n",
    "        self.prompt = template\n",
    "        self.gemma_causal_lm = gemma_lm\n",
    "\n",
    "    def query(self, artist, title):\n",
    "        prompt = self.prompt.format(Artist=artist, Title=title, Song=\"\")\n",
    "        tokenized_prompt = tokenizer(prompt, return_tensors=\"jax\")\n",
    "        word_count = len(prompt.split())\n",
    "\n",
    "        def generation_callback(logits, state):\n",
    "            nonlocal word_count\n",
    "            word_count += 1\n",
    "            return custom_sample(logits, word_count)\n",
    "\n",
    "        response = self.gemma_causal_lm.generate(\n",
    "            prompt,\n",
    "            max_length=self.max_length,\n",
    "            stop_token_ids=[tokenizer.token_to_id(\"[EOS]\") or tokenizer.eos_token_id],\n",
    "            sampler=generation_callback\n",
    "        )\n",
    "        display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Give me a song titled \"i love you\" in style of artist \"taylor swift\" Song: Artist: Album: Year: Label: Genre: Length: Lyrics: I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love you I love [eos]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class GemmaQA:\n",
    "    def __init__(self, max_length=1024, word_limit=300):\n",
    "        self.max_length = max_length\n",
    "        self.word_limit = word_limit  # Hard limit of 300 words\n",
    "        # self.prompt = \"give me a song titled \\\"{Title}\\\" in style of artist \\\"{Artist}\\\"\\n\\n\\nsong:\\n{Song}\".lower()\n",
    "        self.gemma_causal_lm = gemma_lm\n",
    "\n",
    "    def query(self, artist, title):\n",
    "        prompt = template.format(Artist=artist.lower(), Title=title.lower(), Song=\"\")\n",
    "        # Generate the full response\n",
    "        response = self.gemma_causal_lm.generate(\n",
    "            prompt,\n",
    "            max_length=self.max_length,\n",
    "            stop_token_ids=[self.gemma_causal_lm.preprocessor.tokenizer.token_to_id(\"[eos]\") or self.gemma_causal_lm.preprocessor.tokenizer.eos_token_id]\n",
    "        )\n",
    "        # Enforce 300-word limit\n",
    "        limited_response = self._limit_words(response, self.word_limit)\n",
    "        display(Markdown(limited_response))\n",
    "\n",
    "    def _limit_words(self, text, max_words):\n",
    "        # Split text into words\n",
    "        words = text.split()\n",
    "        # Count words in the prompt part to subtract from the total limit\n",
    "        prompt_words = 0#len(self.prompt.format(Artist=\"dummy\", Title=\"dummy\", Song=\"\").split())\n",
    "        # Adjust max_words to account for prompt words\n",
    "        song_words_limit = max_words - prompt_words\n",
    "        if song_words_limit <= 0:\n",
    "            return text  # If prompt itself exceeds limit, return as is (unlikely)\n",
    "        # Take only the allowed number of words after the prompt\n",
    "        limited_words = words[:prompt_words + song_words_limit]\n",
    "        # Reconstruct the text\n",
    "        limited_text = \" \".join(limited_words)\n",
    "        # Append [eos] if it’s not already present and we’ve truncated\n",
    "        if \"[eos]\" not in limited_text.lower() and len(words) > (prompt_words + song_words_limit):\n",
    "            limited_text += \" [eos]\"\n",
    "        return limited_text\n",
    "\n",
    "# Example usage\n",
    "g = GemmaQA()\n",
    "g.query(\"taylor swift\", \"i love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Give me a song titled \"{Title}\" in style of artist \"{Artist}\"\\n\\n\\nSong:\\n{Song}'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=GemmaQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GemmaTokenizer' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtaylor swift\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi love you\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[135], line 30\u001b[0m, in \u001b[0;36mGemmaQA.query\u001b[0;34m(self, artist, title)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, artist, title):\n\u001b[1;32m     29\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_template\u001b[38;5;241m.\u001b[39mformat(Artist\u001b[38;5;241m=\u001b[39martist, Title\u001b[38;5;241m=\u001b[39mtitle, Song\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     input_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mencode(prompt)\n\u001b[1;32m     31\u001b[0m     generated_tokens \u001b[38;5;241m=\u001b[39m input_tokens\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     32\u001b[0m     word_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(prompt\u001b[38;5;241m.\u001b[39msplit())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GemmaTokenizer' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "g.query(\"taylor swift\",\"i love you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GemmaQA:\n",
    "    def __init__(self, max_length=1024):\n",
    "        self.max_length = max_length\n",
    "        self.gemma_causal_lm = gemma_lm  # Assuming this is your model instance\n",
    "\n",
    "    def query(self, artist, title):\n",
    "        prompt = template.format(Title=title.lower(),Artist=artist.lower(),Song=\"\")\n",
    "        response = self.gemma_causal_lm.generate(prompt, max_length=self.max_length)\n",
    "        # Apply post-processing to reduce repetitions\n",
    "        response = self._reduce_repetitions(response)\n",
    "        return response\n",
    "\n",
    "    def _reduce_repetitions(self, text, max_repeats=3):\n",
    "        lines = text.split(\"\\n\")\n",
    "        seen = {}\n",
    "        filtered_lines = []\n",
    "        for line in lines:\n",
    "            seen[line] = seen.get(line, 0) + 1\n",
    "            if seen[line] <= max_repeats:\n",
    "                filtered_lines.append(line)\n",
    "            else:\n",
    "                break  # Stop adding lines once repetition limit is reached\n",
    "        return \"\\n\".join(filtered_lines)\n",
    "\n",
    "# Example usage\n",
    "g = GemmaQA()\n",
    "# print(g.query(\"Taylor Swift\", \"I love you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Give me a song titled \"h\" in style of artist \"ariana grande\"\\n\\n\\nSong:\\nArtist:\\nAlbum:\\nYear:\\nGenre:\\nLength:\\nLyrics:\\nI\\'m a little bit of a mess\\nI\\'m a little bit of a mess\\nI\\'m a little bit of a mess'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.query(\"ariana grande\",\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a song titled \"i love you\" in style of artist \"taylor swift\"\n",
      "\n",
      "\n",
      "Song:\n",
      "i'm not the kind of girl you wanna see come near me i'm not the kind of girl you wanna see with someone else the things you said were so low so dumb i was so young i was insecure and crazy i was insecure and insecure   i was insecure   i was insecure and crazy i was insecure and insecure   i was insecure and i was insecure and i was insecure and i was insecure and i was insecure and i was insecure   you said she's scared of me i'm the one who's scared of you i'm the one who's scared of you i'm the one who's scared of you i'm the one who's scared of you i'm the one who's scared of you i'm the one who's scared of you i'm the one who's scared of you i'm the one who's scared of you i'm the one who's scared of you i'm the one who's scared of you [EOS]\n"
     ]
    }
   ],
   "source": [
    "class GemmaQA:\n",
    "    def __init__(self, max_length=1024):\n",
    "        self.max_length = max_length\n",
    "        self.gemma_causal_lm = gemma_lm  # Assuming this is your model instance\n",
    "\n",
    "    def query(self, artist, title):\n",
    "        prompt = template.format(Title=title.lower(),Artist=artist.lower(),Song=\"\")\n",
    "        response = self.gemma_causal_lm.generate(prompt, max_length=self.max_length)\n",
    "        # Apply post-processing to reduce repetitions\n",
    "        response = self._reduce_repetitions(response)\n",
    "        return response\n",
    "\n",
    "    def _reduce_repetitions(self, text, max_repeats=3):\n",
    "        lines = text.split(\"\\n\")\n",
    "        seen = {}\n",
    "        filtered_lines = []\n",
    "        for line in lines:\n",
    "            seen[line] = seen.get(line, 0) + 1\n",
    "            if seen[line] <= max_repeats:\n",
    "                filtered_lines.append(line)\n",
    "            else:\n",
    "                break  # Stop adding lines once repetition limit is reached\n",
    "        return \"\\n\".join(filtered_lines)\n",
    "\n",
    "# Example usage\n",
    "g = GemmaQA()\n",
    "print(g.query(\"Taylor Swift\", \"I love you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Give me a song titled \"{Title}\" in style of artist \"{Artist}\"\\n\\n\\nSong:\\n{Song}'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"i'm runnin' through the jungle i'm running on a lie i'm a city typetypbing like  béné and my even's rollin' like that shh this beat is so sweet that bitch can't fuck me good good  pre you go call me baby like like i'm your pup 'cause you stick it in your nose than pass it to me like a blunt and i'm like okay ooh ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy ayy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i'm runnin' through the jungle i'm running on a lie i'm\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_lm.generate(, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(Config.checkpoint_dir, \"checkpoint_epoch_10.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reloc/miniconda3/envs/mtestenv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 76 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "gemma_lm.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_lm.compile(sampler=hub.samplers.TopKSampler(k=10, temperature=0.95))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: my presence sweet and my presence sweet and my presence sweet   summer after high school when we hit the corner store with your gangsta love and smoking joe the names i started in the gutter but everywhere i go they keep telling me\n",
      "Iteration 2:  the same old song but mother i'm the same old me  pre i can't go a year without you and i fall with you i fall with you i fall with you   i can't go back to one i said i said i'm gonna leave you and i said i said leave you  pre i said i said i don't wanna go back to one i said i said go on and bla bla bla i said go on and pput me down pput me down pput me down pp pretensions waiting at the end of the line i said go on and pp pretensions holding you down pput me down pp palpitations you were always so my favorite song forever like a knife in the wind lights will guide you home and i heard my phone ring i i knew i was gonna wake up chained from the back of a horse and singing the blues saying i said leave me down pput me down pput me down pput me down pppanonymous [EOS]\n",
      "Iteration 3: \n",
      "Iteration 4: \n",
      "Iteration 5: \n",
      "Final Output: Give me a song titled \"\" in style of artist \"taylor swift\"\n",
      "\n",
      "\n",
      "Song:\n",
      "my presence sweet and my presence sweet and my presence sweet   summer after high school when we hit the corner store with your gangsta love and smoking joe the names i started in the gutter but everywhere i go they keep telling me the same old song but mother i'm the same old me  pre i can't go a year without you and i fall with you i fall with you i fall with you   i can't go back to one i said i said i'm gonna leave you and i said i said leave you  pre i said i said i don't wanna go back to one i said i said go on and bla bla bla i said go on and pput me down pput me down pput me down pp pretensions waiting at the end of the line i said go on and pp pretensions holding you down pput me down pp palpitations you were always so my favorite song forever like a knife in the wind lights will guide you home and i heard my phone ring i i knew i was gonna wake up chained from the back of a horse and singing the blues saying i said leave me down pput me down pput me down pput me down pppanonymous [EOS]\n"
     ]
    }
   ],
   "source": [
    "gemma_lm.compile(sampler=hub.samplers.TopKSampler(k=10, temperature=0.9))\n",
    "\n",
    "prompt = \"Give me a song titled \\\"\\\" in style of artist \\\"taylor swift\\\"\\n\\n\\nSong:\\n\"\n",
    "generated_text = prompt\n",
    "num_iterations = 5\n",
    "tokens_per_iteration = 1\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    next_chunk = gemma_lm.generate(generated_text, max_length=len(generated_text) + tokens_per_iteration)\n",
    "    newly_generated = next_chunk[len(generated_text):]\n",
    "    # --- Here you would implement your repetition checking and potential adjustments ---\n",
    "    generated_text = next_chunk\n",
    "    print(f\"Iteration {_ + 1}: {newly_generated}\")\n",
    "\n",
    "print(\"Final Output:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Give me a song titled \\\"{Title}\\\" in style of artist \\\"{Artist}\\\"\\n\\n\\nSong:\\n{Song}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a soldier to the finish i will retire with the ring on my thumb and i will retire with a bad heart but i will retire with a ring on my thumb [EOS]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_lm.generate(\"I am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 04:24:00.807824: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT64 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Give me a song titled \"i love you\" in style of artist \"taylor swift\"\n",
       "\n",
       "\n",
       "Song:\n",
       "i'm standing here pickin' it up shattering the illusion but i'm standing here picking it up smashing the illusion i'm standing here stuck to the pavement the putty stash you stuck my nails done the fight but i'm still a believer my eyes are wide should've kept you with me i'm standing here again my heart now is breaking in front of your eyes i'm standing here in your doorway but i'm not leaving this time i'm standing here again my heart now is breaking in front of your eyes   i'm standing there again my heart now is breaking in front of your eyes again and i'm standing in your doorway   they say i need to go on lonely nights don't even wanna see you cry caricature bet you does like that i'm walking in my shoes and i'm coming back to you oh  pre oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh oh"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class GemmaQA:\n",
    "    def __init__(self, max_length=1024):\n",
    "        self.max_length = max_length\n",
    "        self.prompt = template\n",
    "        self.gemma_causal_lm = gemma_lm\n",
    "\n",
    "    def query(self, artist, title):\n",
    "        # Lowercase artist and title to match training\n",
    "        prompt = self.prompt.format(Artist=artist.lower(), Title=title.lower(), Song=\"\")\n",
    "        response = self.gemma_causal_lm.generate(\n",
    "            prompt,\n",
    "            max_length=self.max_length,\n",
    "            stop_token_ids=[self.gemma_causal_lm.preprocessor.tokenizer.token_to_id(\"[eos]\") or self.gemma_causal_lm.preprocessor.tokenizer.eos_token_id]\n",
    "        )\n",
    "        display(Markdown(response))\n",
    "\n",
    "# Example usage\n",
    "g = GemmaQA()\n",
    "g.query(\"Taylor Swift\", \"I love you\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
